{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zs2woWv_HoE8"
      },
      "source": [
        "# Build a classification model: Delicious Asian and Indian Cuisines"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iDFOb3ebHwQC"
      },
      "source": [
        "## Cuisine classifiers 1\n",
        "\n",
        "In this lesson, we'll explore a variety of classifiers to *predict a given national cuisine based on a group of ingredients.* While doing so, we'll learn more about some of the ways that algorithms can be leveraged for classification tasks.\n",
        "\n",
        "### [**Pre-lecture quiz**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/21/)\n",
        "\n",
        "### **Preparation**\n",
        "\n",
        "This lesson builds up on our [previous lesson](https://github.com/microsoft/ML-For-Beginners/blob/main/4-Classification/1-Introduction/solution/lesson_10-R.ipynb) where we:\n",
        "\n",
        "-   Made a gentle introduction to classifications using a dataset about all the brilliant cuisines of Asia and India ğŸ˜‹.\n",
        "\n",
        "-   Explored some [dplyr verbs](https://dplyr.tidyverse.org/) to prep and clean our data.\n",
        "\n",
        "-   Made beautiful visualizations using ggplot2.\n",
        "\n",
        "-   Demonstrated how to deal with imbalanced data by preprocessing it using [recipes](https://recipes.tidymodels.org/articles/Simple_Example.html).\n",
        "\n",
        "-   Demonstrated how to `prep` and `bake` our recipe to confirm that it will work as supposed to.\n",
        "\n",
        "#### **Prerequisite**\n",
        "\n",
        "For this lesson, we'll require the following packages to clean, prep and visualize our data:\n",
        "\n",
        "-   `tidyverse`: The [tidyverse](https://www.tidyverse.org/) is a [collection of R packages](https://www.tidyverse.org/packages) designed to makes data science faster, easier and more fun!\n",
        "\n",
        "-   `tidymodels`: The [tidymodels](https://www.tidymodels.org/) framework is a [collection of packages](https://www.tidymodels.org/packages/) for modeling and machine learning.\n",
        "\n",
        "\n",
        "-   `themis`: The [themis package](https://themis.tidymodels.org/) provides Extra Recipes Steps for Dealing with Unbalanced Data.\n",
        "\n",
        "-   `nnet`: The [nnet package](https://cran.r-project.org/web/packages/nnet/nnet.pdf) provides functions for estimating feed-forward neural networks with a single hidden layer, and for multinomial logistic regression models.\n",
        "\n",
        "You can have them installed as:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4V85BGCjII7F"
      },
      "source": [
        "\n",
        "`install.packages(c(\"tidyverse\", \"tidymodels\", \"DataExplorer\", \"here\"))`\n",
        "\n",
        "Alternatively, the script below checks whether you have the packages required to complete this module and installs them for you in case they are missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an5NPyyKIKNR",
        "outputId": "834d5e74-f4b8-49f9-8ab5-4c52ff2d7bc8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading required package: pacman\n",
            "\n"
          ]
        }
      ],
      "source": [
        "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
        "\n",
        "pacman::p_load(tidyverse, tidymodels, themis, here)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0ax9GQLBINVv"
      },
      "source": [
        "Now, let's hit the ground running!\n",
        "\n",
        "## 1. Split the data into training and test sets.\n",
        "\n",
        "We'll start by picking a few steps from our previous lesson.\n",
        "\n",
        "### Drop the most common ingredients that create confusion between distinct cuisines, using `dplyr::select()`.\n",
        "\n",
        "Everyone loves rice, garlic and ginger!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "jhCrrH22IWVR",
        "outputId": "d444a85c-1d8b-485f-bc4f-8be2e8f8217c",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[22mNew names:\n",
            "\u001b[36mâ€¢\u001b[39m `` -> `...1`\n",
            "\u001b[1mRows: \u001b[22m\u001b[34m2448\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m385\u001b[39m\n",
            "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m   (1): cuisine\n",
            "\u001b[32mdbl\u001b[39m (384): ...1, almond, angelica, anise, anise_seed, apple, apple_brandy, a...\n",
            "\n",
            "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 381</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>almond</th><th scope=col>angelica</th><th scope=col>anise</th><th scope=col>anise_seed</th><th scope=col>apple</th><th scope=col>apple_brandy</th><th scope=col>apricot</th><th scope=col>armagnac</th><th scope=col>artemisia</th><th scope=col>â‹¯</th><th scope=col>whiskey</th><th scope=col>white_bread</th><th scope=col>white_wine</th><th scope=col>whole_grain_wheat_flour</th><th scope=col>wine</th><th scope=col>wood</th><th scope=col>yam</th><th scope=col>yeast</th><th scope=col>yogurt</th><th scope=col>zucchini</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>â‹¯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>indian</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>indian</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>indian</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>indian</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>indian</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 381\n",
              "\\begin{tabular}{lllllllllllllllllllll}\n",
              " cuisine & almond & angelica & anise & anise\\_seed & apple & apple\\_brandy & apricot & armagnac & artemisia & â‹¯ & whiskey & white\\_bread & white\\_wine & whole\\_grain\\_wheat\\_flour & wine & wood & yam & yeast & yogurt & zucchini\\\\\n",
              " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & â‹¯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t indian & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t indian & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t indian & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t indian & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t indian & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 381\n",
              "\n",
              "| cuisine &lt;fct&gt; | almond &lt;dbl&gt; | angelica &lt;dbl&gt; | anise &lt;dbl&gt; | anise_seed &lt;dbl&gt; | apple &lt;dbl&gt; | apple_brandy &lt;dbl&gt; | apricot &lt;dbl&gt; | armagnac &lt;dbl&gt; | artemisia &lt;dbl&gt; | â‹¯ â‹¯ | whiskey &lt;dbl&gt; | white_bread &lt;dbl&gt; | white_wine &lt;dbl&gt; | whole_grain_wheat_flour &lt;dbl&gt; | wine &lt;dbl&gt; | wood &lt;dbl&gt; | yam &lt;dbl&gt; | yeast &lt;dbl&gt; | yogurt &lt;dbl&gt; | zucchini &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
              "| indian | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| indian | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| indian | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| indian | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| indian | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine almond angelica anise anise_seed apple apple_brandy apricot armagnac\n",
              "1 indian  0      0        0     0          0     0            0       0       \n",
              "2 indian  1      0        0     0          0     0            0       0       \n",
              "3 indian  0      0        0     0          0     0            0       0       \n",
              "4 indian  0      0        0     0          0     0            0       0       \n",
              "5 indian  0      0        0     0          0     0            0       0       \n",
              "  artemisia â‹¯ whiskey white_bread white_wine whole_grain_wheat_flour wine wood\n",
              "1 0         â‹¯ 0       0           0          0                       0    0   \n",
              "2 0         â‹¯ 0       0           0          0                       0    0   \n",
              "3 0         â‹¯ 0       0           0          0                       0    0   \n",
              "4 0         â‹¯ 0       0           0          0                       0    0   \n",
              "5 0         â‹¯ 0       0           0          0                       0    0   \n",
              "  yam yeast yogurt zucchini\n",
              "1 0   0     0      0       \n",
              "2 0   0     0      0       \n",
              "3 0   0     0      0       \n",
              "4 0   0     0      0       \n",
              "5 0   0     1      0       "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>n</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>korean  </td><td>799</td></tr>\n",
              "\t<tr><td>indian  </td><td>598</td></tr>\n",
              "\t<tr><td>chinese </td><td>442</td></tr>\n",
              "\t<tr><td>japanese</td><td>320</td></tr>\n",
              "\t<tr><td>thai    </td><td>289</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 2\n",
              "\\begin{tabular}{ll}\n",
              " cuisine & n\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t korean   & 799\\\\\n",
              "\t indian   & 598\\\\\n",
              "\t chinese  & 442\\\\\n",
              "\t japanese & 320\\\\\n",
              "\t thai     & 289\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 2\n",
              "\n",
              "| cuisine &lt;fct&gt; | n &lt;int&gt; |\n",
              "|---|---|\n",
              "| korean   | 799 |\n",
              "| indian   | 598 |\n",
              "| chinese  | 442 |\n",
              "| japanese | 320 |\n",
              "| thai     | 289 |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine  n  \n",
              "1 korean   799\n",
              "2 indian   598\n",
              "3 chinese  442\n",
              "4 japanese 320\n",
              "5 thai     289"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the original cuisines data\n",
        "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
        "\n",
        "# Drop id column, rice, garlic and ginger from our original data set\n",
        "df_select <- df %>% \n",
        "  select(-c(1, rice, garlic, ginger)) %>%\n",
        "  # Encode cuisine column as categorical\n",
        "  mutate(cuisine = factor(cuisine))\n",
        "\n",
        "# Display new data set\n",
        "df_select %>% \n",
        "  slice_head(n = 5)\n",
        "\n",
        "# Display distribution of cuisines\n",
        "df_select %>% \n",
        "  count(cuisine) %>% \n",
        "  arrange(desc(n))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AYTjVyajIdny"
      },
      "source": [
        "Perfect! Now, time to split the data such that 70% of the data goes to training and 30% goes to testing. We'll also apply a `stratification` technique when splitting the data to `maintain the proportion of each cuisine` in the training and validation datasets.\n",
        "\n",
        "[rsample](https://rsample.tidymodels.org/), a package in Tidymodels, provides infrastructure for efficient data splitting and resampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "w5FWIkEiIjdN",
        "outputId": "2e195fd9-1a8f-4b91-9573-cce5582242df",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training cases: 1712\n",
            "Test cases: 736"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 381</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>almond</th><th scope=col>angelica</th><th scope=col>anise</th><th scope=col>anise_seed</th><th scope=col>apple</th><th scope=col>apple_brandy</th><th scope=col>apricot</th><th scope=col>armagnac</th><th scope=col>artemisia</th><th scope=col>â‹¯</th><th scope=col>whiskey</th><th scope=col>white_bread</th><th scope=col>white_wine</th><th scope=col>whole_grain_wheat_flour</th><th scope=col>wine</th><th scope=col>wood</th><th scope=col>yam</th><th scope=col>yeast</th><th scope=col>yogurt</th><th scope=col>zucchini</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>â‹¯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>chinese</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>chinese</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>chinese</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>chinese</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><td>chinese</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>â‹¯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 381\n",
              "\\begin{tabular}{lllllllllllllllllllll}\n",
              " cuisine & almond & angelica & anise & anise\\_seed & apple & apple\\_brandy & apricot & armagnac & artemisia & â‹¯ & whiskey & white\\_bread & white\\_wine & whole\\_grain\\_wheat\\_flour & wine & wood & yam & yeast & yogurt & zucchini\\\\\n",
              " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & â‹¯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t chinese & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t chinese & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t chinese & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t chinese & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\t chinese & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & â‹¯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 381\n",
              "\n",
              "| cuisine &lt;fct&gt; | almond &lt;dbl&gt; | angelica &lt;dbl&gt; | anise &lt;dbl&gt; | anise_seed &lt;dbl&gt; | apple &lt;dbl&gt; | apple_brandy &lt;dbl&gt; | apricot &lt;dbl&gt; | armagnac &lt;dbl&gt; | artemisia &lt;dbl&gt; | â‹¯ â‹¯ | whiskey &lt;dbl&gt; | white_bread &lt;dbl&gt; | white_wine &lt;dbl&gt; | whole_grain_wheat_flour &lt;dbl&gt; | wine &lt;dbl&gt; | wood &lt;dbl&gt; | yam &lt;dbl&gt; | yeast &lt;dbl&gt; | yogurt &lt;dbl&gt; | zucchini &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
              "| chinese | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
              "| chinese | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
              "| chinese | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| chinese | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "| chinese | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | â‹¯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine almond angelica anise anise_seed apple apple_brandy apricot armagnac\n",
              "1 chinese 0      0        0     0          0     0            0       0       \n",
              "2 chinese 0      0        0     0          0     0            0       0       \n",
              "3 chinese 0      0        0     0          0     0            0       0       \n",
              "4 chinese 0      0        0     0          0     0            0       0       \n",
              "5 chinese 0      0        0     0          0     0            0       0       \n",
              "  artemisia â‹¯ whiskey white_bread white_wine whole_grain_wheat_flour wine wood\n",
              "1 0         â‹¯ 0       0           0          0                       1    0   \n",
              "2 0         â‹¯ 0       0           0          0                       1    0   \n",
              "3 0         â‹¯ 0       0           0          0                       0    0   \n",
              "4 0         â‹¯ 0       0           0          0                       0    0   \n",
              "5 0         â‹¯ 0       0           0          0                       0    0   \n",
              "  yam yeast yogurt zucchini\n",
              "1 0   0     0      0       \n",
              "2 0   0     0      0       \n",
              "3 0   0     0      0       \n",
              "4 0   0     0      0       \n",
              "5 0   0     0      0       "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>n</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>korean  </td><td>559</td></tr>\n",
              "\t<tr><td>indian  </td><td>418</td></tr>\n",
              "\t<tr><td>chinese </td><td>309</td></tr>\n",
              "\t<tr><td>japanese</td><td>224</td></tr>\n",
              "\t<tr><td>thai    </td><td>202</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 2\n",
              "\\begin{tabular}{ll}\n",
              " cuisine & n\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t korean   & 559\\\\\n",
              "\t indian   & 418\\\\\n",
              "\t chinese  & 309\\\\\n",
              "\t japanese & 224\\\\\n",
              "\t thai     & 202\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 2\n",
              "\n",
              "| cuisine &lt;fct&gt; | n &lt;int&gt; |\n",
              "|---|---|\n",
              "| korean   | 559 |\n",
              "| indian   | 418 |\n",
              "| chinese  | 309 |\n",
              "| japanese | 224 |\n",
              "| thai     | 202 |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine  n  \n",
              "1 korean   559\n",
              "2 indian   418\n",
              "3 chinese  309\n",
              "4 japanese 224\n",
              "5 thai     202"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the core Tidymodels packages into R session\n",
        "library(tidymodels)\n",
        "\n",
        "# Create split specification\n",
        "set.seed(2056)\n",
        "cuisines_split <- initial_split(data = df_select,\n",
        "                                strata = cuisine,\n",
        "                                prop = 0.7)\n",
        "\n",
        "# Extract the data in each split\n",
        "cuisines_train <- training(cuisines_split)\n",
        "cuisines_test <- testing(cuisines_split)\n",
        "\n",
        "# Print the number of cases in each split\n",
        "cat(\"Training cases: \", nrow(cuisines_train), \"\\n\",\n",
        "    \"Test cases: \", nrow(cuisines_test), sep = \"\")\n",
        "\n",
        "# Display the first few rows of the training set\n",
        "cuisines_train %>% \n",
        "  slice_head(n = 5)\n",
        "\n",
        "\n",
        "# Display distribution of cuisines in the training set\n",
        "cuisines_train %>% \n",
        "  count(cuisine) %>% \n",
        "  arrange(desc(n))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "daBi9qJNIwqW"
      },
      "source": [
        "## 2. Deal with imbalanced data\n",
        "\n",
        "As you might have noticed in the original data set as well as in our training set, there is quite an unequal distribution in the number of cuisines. Korean cuisines are *almost* 3 times Thai cuisines. Imbalanced data often has negative effects on the model performance. Many models perform best when the number of observations is equal and, thus, tend to struggle with unbalanced data.\n",
        "\n",
        "There are majorly two ways of dealing with imbalanced data sets:\n",
        "\n",
        "-   adding observations to the minority class: `Over-sampling` e.g using a SMOTE algorithm which synthetically generates new examples of the minority class using nearest neighbors of these cases.\n",
        "\n",
        "-   removing observations from majority class: `Under-sampling`\n",
        "\n",
        "In our previous lesson, we demonstrated how to deal with imbalanced data sets using a `recipe`. A recipe can be thought of as a blueprint that describes what steps should be applied to a data set in order to get it ready for data analysis. In our case, we want to have an equal distribution in the number of our cuisines for our `training set`. Let's get right into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Az6LFBGxI1X0",
        "outputId": "29d71d85-64b0-4e62-871e-bcd5398573b6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Recipe\n",
              "\n",
              "Inputs:\n",
              "\n",
              "      role #variables\n",
              "   outcome          1\n",
              " predictor        380\n",
              "\n",
              "Operations:\n",
              "\n",
              "SMOTE based on cuisine"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load themis package for dealing with imbalanced data\n",
        "library(themis)\n",
        "\n",
        "# Create a recipe for preprocessing training data\n",
        "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>% \n",
        "  step_smote(cuisine)\n",
        "\n",
        "# Print recipe\n",
        "cuisines_recipe"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NBL3PqIWJBBB"
      },
      "source": [
        "You can of course go ahead and confirm (using prep+bake) that the recipe will work as you expect it - all the cuisine labels having `559` observations.\n",
        "\n",
        "Since we'll be using this recipe as a preprocessor for modeling, a `workflow()` will do all the prep and bake for us, so we won't have to manually estimate the recipe.\n",
        "\n",
        "Now we are ready to train a model ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»!\n",
        "\n",
        "## 3. Choosing your classifier\n",
        "\n",
        "<p >\n",
        "   <img src=\"../../images/parsnip.jpg\"\n",
        "   width=\"600\"/>\n",
        "   <figcaption>Artwork by @allison_horst</figcaption>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a6DLAZ3vJZ14"
      },
      "source": [
        "Now we have to decide which algorithm to use for the job ğŸ¤”.\n",
        "\n",
        "In Tidymodels, the [`parsnip package`](https://parsnip.tidymodels.org/index.html) provides consistent interface for working with models across different engines (packages). Please see the parsnip documentation to explore [model types & engines](https://www.tidymodels.org/find/parsnip/#models) and their corresponding [model arguments](https://www.tidymodels.org/find/parsnip/#model-args). The variety is quite bewildering at first sight. For instance, the following methods all include classification techniques:\n",
        "\n",
        "-   C5.0 Rule-Based Classification Models\n",
        "\n",
        "-   Flexible Discriminant Models\n",
        "\n",
        "-   Linear Discriminant Models\n",
        "\n",
        "-   Regularized Discriminant Models\n",
        "\n",
        "-   Logistic Regression Models\n",
        "\n",
        "-   Multinomial Regression Models\n",
        "\n",
        "-   Naive Bayes Models\n",
        "\n",
        "-   Support Vector Machines\n",
        "\n",
        "-   Nearest Neighbors\n",
        "\n",
        "-   Decision Trees\n",
        "\n",
        "-   Ensemble methods\n",
        "\n",
        "-   Neural Networks\n",
        "\n",
        "The list goes on!\n",
        "\n",
        "### **What classifier to go with?**\n",
        "\n",
        "So, which classifier should you choose? Often, running through several and looking for a good result is a way to test.\n",
        "\n",
        "> AutoML solves this problem neatly by running these comparisons in the cloud, allowing you to choose the best algorithm for your data. Try it [here](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)\n",
        "\n",
        "Also the choice of classifier depends on our problem. For instance, when the outcome can be categorized into `more than two classes`, like in our case, you must use a `multiclass classification algorithm` as opposed to `binary classification.`\n",
        "\n",
        "### **A better approach**\n",
        "\n",
        "A better way than wildly guessing, however, is to follow the ideas on this downloadable [ML Cheat sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Here, we discover that, for our multiclass problem, we have some choices:\n",
        "\n",
        "<p >\n",
        "   <img src=\"../../images/cheatsheet.png\"\n",
        "   width=\"500\"/>\n",
        "   <figcaption>A section of Microsoft's Algorithm Cheat Sheet, detailing multiclass classification options</figcaption>\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gWMsVcbBJemu"
      },
      "source": [
        "### **Reasoning**\n",
        "\n",
        "Let's see if we can reason our way through different approaches given the constraints we have:\n",
        "\n",
        "-   **Deep Neural networks are too heavy**. Given our clean, but minimal dataset, and the fact that we are running training locally via notebooks, deep neural networks are too heavyweight for this task.\n",
        "\n",
        "-   **No two-class classifier**. We do not use a two-class classifier, so that rules out one-vs-all.\n",
        "\n",
        "-   **Decision tree or logistic regression could work**. A decision tree might work, or multinomial regression/multiclass logistic regression for multiclass data.\n",
        "\n",
        "-   **Multiclass Boosted Decision Trees solve a different problem**. The multiclass boosted decision tree is most suitable for nonparametric tasks, e.g. tasks designed to build rankings, so it is not useful for us.\n",
        "\n",
        "Also, normally before embarking on more complex machine learning models e.g ensemble methods, it's a good idea to build the simplest possible model to get an idea of what is going on. So for this lesson, we'll start with a `multinomial regression` model.\n",
        "\n",
        "> Logistic regression is a technique used when the outcome variable is categorical (or nominal). For Binary logistic regression the number of outcome variables is two, whereas the number of outcome variables for multinomial logistic regression is more than two. See [Advanced Regression Methods](https://bookdown.org/chua/ber642_advanced_regression/multinomial-logistic-regression.html) for further reading.\n",
        "\n",
        "## 4. Train and evaluate a Multinomial logistic regression model.\n",
        "\n",
        "In Tidymodels, `parsnip::multinom_reg()`, defines a model that uses linear predictors to predict multiclass data using the multinomial distribution. See `?multinom_reg()` for the different ways/engines you can use to fit this model.\n",
        "\n",
        "For this example, we'll fit a Multinomial regression model via the default [nnet](https://cran.r-project.org/web/packages/nnet/nnet.pdf) engine.\n",
        "\n",
        "> I picked a value for `penalty` sort of randomly. There are better ways to choose this value that is, by using `resampling` and `tuning` the model which we'll discuss later.\n",
        ">\n",
        "> See [Tidymodels: Get Started](https://www.tidymodels.org/start/tuning/) in case you want to learn more on how to tune model hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "Wq_fcyQiJvfG",
        "outputId": "c30449c7-3864-4be7-f810-72a003743e2d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Multinomial Regression Model Specification (classification)\n",
              "\n",
              "Main Arguments:\n",
              "  penalty = 1\n",
              "\n",
              "Engine-Specific Arguments:\n",
              "  MaxNWts = 2086\n",
              "\n",
              "Computational engine: nnet \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a multinomial regression model specification\n",
        "mr_spec <- multinom_reg(penalty = 1) %>% \n",
        "  set_engine(\"nnet\", MaxNWts = 2086) %>% \n",
        "  set_mode(\"classification\")\n",
        "\n",
        "# Print model specification\n",
        "mr_spec"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSbzDfgJ0zh"
      },
      "source": [
        "Great job ğŸ¥³! Now that we have a recipe and a model specification, we need to find a way of bundling them together into an object that will first preprocess the data then fit the model on the preprocessed data and also allow for potential post-processing activities. In Tidymodels, this convenient object is called a [`workflow`](https://workflows.tidymodels.org/) and conveniently holds your modeling components! This is what we'd call *pipelines* in *Python*.\n",
        "\n",
        "So let's bundle everything up into a workflow!ğŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Sc1TfPA4Ke3_",
        "outputId": "82c70013-e431-4e7e-cef6-9fcf8aad4a6c",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
              "\u001b[3mPreprocessor:\u001b[23m Recipe\n",
              "\u001b[3mModel:\u001b[23m multinom_reg()\n",
              "\n",
              "â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "1 Recipe Step\n",
              "\n",
              "â€¢ step_smote()\n",
              "\n",
              "â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Multinomial Regression Model Specification (classification)\n",
              "\n",
              "Main Arguments:\n",
              "  penalty = 1\n",
              "\n",
              "Engine-Specific Arguments:\n",
              "  MaxNWts = 2086\n",
              "\n",
              "Computational engine: nnet \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Bundle recipe and model specification\n",
        "mr_wf <- workflow() %>% \n",
        "  add_recipe(cuisines_recipe) %>% \n",
        "  add_model(mr_spec)\n",
        "\n",
        "# Print out workflow\n",
        "mr_wf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TNQ8i85aKf9L"
      },
      "source": [
        "Workflows ğŸ‘ŒğŸ‘Œ! A **`workflow()`** can be fit in much the same way a model can. So, time to train a model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GMbdfVmTKkJI",
        "outputId": "adf9ebdf-d69d-4a64-e9fd-e06e5322292e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
              "\u001b[3mPreprocessor:\u001b[23m Recipe\n",
              "\u001b[3mModel:\u001b[23m multinom_reg()\n",
              "\n",
              "â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "1 Recipe Step\n",
              "\n",
              "â€¢ step_smote()\n",
              "\n",
              "â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Call:\n",
              "nnet::multinom(formula = ..y ~ ., data = data, decay = ~1, MaxNWts = ~2086, \n",
              "    trace = FALSE)\n",
              "\n",
              "Coefficients:\n",
              "         (Intercept)     almond angelica         anise anise_seed       apple\n",
              "indian    0.19723325  0.2409661        0 -5.004955e-05 -0.1657635 -0.05769734\n",
              "japanese  0.13961959 -0.6262400        0 -1.169155e-04 -0.4893596 -0.08585717\n",
              "korean    0.22377347 -0.1833485        0 -5.560395e-05 -0.2489401 -0.15657804\n",
              "thai     -0.04336577 -0.6106258        0  4.903828e-04 -0.5782866  0.63451105\n",
              "         apple_brandy     apricot armagnac   artemisia artichoke   asparagus\n",
              "indian              0  0.37042636        0 -0.09122797         0 -0.27181970\n",
              "japanese            0  0.28895643        0 -0.12651100         0  0.14054037\n",
              "korean              0 -0.07981259        0  0.55756709         0 -0.66979948\n",
              "thai                0 -0.33160904        0 -0.10725182         0 -0.02602152\n",
              "             avocado       bacon baked_potato balm     banana     barley\n",
              "indian   -0.46624197  0.16008055            0    0 -0.2838796  0.2230625\n",
              "japanese  0.90341344  0.02932727            0    0 -0.4142787  2.0953906\n",
              "korean   -0.06925382 -0.35804134            0    0 -0.2686963 -0.7233404\n",
              "thai     -0.21473955 -0.75594439            0    0  0.6784880 -0.4363320\n",
              "         bartlett_pear      basil        bay       bean         beech\n",
              "indian               0 -0.7128756  0.1011587 -0.8777275 -0.0004380795\n",
              "japanese             0  0.1288697  0.9425626 -0.2380748  0.3373437611\n",
              "korean               0 -0.2445193 -0.4744318 -0.8957870 -0.0048784496\n",
              "thai                 0  1.5365848  0.1333256  0.2196970 -0.0113078024\n",
              "               beef beef_broth   beef_liver         beer        beet\n",
              "indian   -0.7985278  0.2430186 -0.035598065 -0.002173738  0.01005813\n",
              "japanese  0.2241875 -0.3653020 -0.139551027  0.128905553  0.04923911\n",
              "korean    0.5366515 -0.6153237  0.213455197 -0.010828645  0.27325423\n",
              "thai      0.1570012 -0.9364154 -0.008032213 -0.035063746 -0.28279823\n",
              "         bell_pepper bergamot       berry bitter_orange black_bean\n",
              "indian    0.49074330        0  0.58947607   0.191256164 -0.1945233\n",
              "japanese  0.09074167        0 -0.25917977  -0.118915977 -0.3442400\n",
              "korean   -0.57876763        0 -0.07874180  -0.007729435 -0.5220672\n",
              "thai      0.92554006        0 -0.07210196  -0.002983296 -0.4614426\n",
              "         black_currant black_mustard_seed_oil black_pepper black_raspberry\n",
              "indian               0             0.38935801   -0.4453495               0\n",
              "japanese             0            -0.05452887   -0.5440869               0\n",
              "korean               0            -0.03929970    0.8025454               0\n",
              "thai                 0            -0.21498372   -0.9854806               0\n",
              "         black_sesame_seed  black_tea   blackberry blackberry_brandy\n",
              "indian          -0.2759246  0.3079977  0.191256164                 0\n",
              "japanese        -0.6101687 -0.1671913 -0.118915977                 0\n",
              "korean           1.5197674 -0.3036261 -0.007729435                 0\n",
              "thai            -0.1755656 -0.1487033 -0.002983296                 0\n",
              "         blue_cheese    blueberry   bone_oil bourbon_whiskey      brandy\n",
              "indian             0  0.216164294 -0.2276744               0  0.22427587\n",
              "japanese           0 -0.119186087  0.3913019               0 -0.15595599\n",
              "korean             0 -0.007821986  0.2854487               0 -0.02562342\n",
              "thai               0 -0.004947048 -0.0253658               0 -0.05715244\n",
              "\n",
              "...\n",
              "and 308 more lines."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train a multinomial regression model\n",
        "mr_fit <- fit(object = mr_wf, data = cuisines_train)\n",
        "\n",
        "mr_fit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tt2BfOxrKmcJ"
      },
      "source": [
        "The output shows the coefficients that the model learned during training.\n",
        "\n",
        "### Evaluate the Trained Model\n",
        "\n",
        "It's time to see how the model performed ğŸ“ by evaluating it on a test set! Let's begin by making predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "CqtckvtsKqax",
        "outputId": "e57fe557-6a68-4217-fe82-173328c5436d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>.pred_class</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>indian</td><td>thai  </td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 2\n",
              "\\begin{tabular}{ll}\n",
              " cuisine & .pred\\_class\\\\\n",
              " <fct> & <fct>\\\\\n",
              "\\hline\n",
              "\t indian & thai  \\\\\n",
              "\t indian & indian\\\\\n",
              "\t indian & indian\\\\\n",
              "\t indian & indian\\\\\n",
              "\t indian & indian\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 2\n",
              "\n",
              "| cuisine &lt;fct&gt; | .pred_class &lt;fct&gt; |\n",
              "|---|---|\n",
              "| indian | thai   |\n",
              "| indian | indian |\n",
              "| indian | indian |\n",
              "| indian | indian |\n",
              "| indian | indian |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine .pred_class\n",
              "1 indian  thai       \n",
              "2 indian  indian     \n",
              "3 indian  indian     \n",
              "4 indian  indian     \n",
              "5 indian  indian     "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "results <- cuisines_test %>% select(cuisine) %>% \n",
        "  bind_cols(mr_fit %>% predict(new_data = cuisines_test))\n",
        "\n",
        "# Print out results\n",
        "results %>% \n",
        "  slice_head(n = 5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8w5N6XsBKss7"
      },
      "source": [
        "Great job! In Tidymodels, evaluating model performance can be done using [yardstick](https://yardstick.tidymodels.org/) - a package used to measure the effectiveness of models using performance metrics. As we did in our logistic regression lesson, let's begin by computing a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "YvODvsLkK0iG",
        "outputId": "bb69da84-1266-47ad-b174-d43b88ca2988",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "          Truth\n",
              "Prediction chinese indian japanese korean thai\n",
              "  chinese       83      1        8     15   10\n",
              "  indian         4    163        1      2    6\n",
              "  japanese      21      5       73     25    1\n",
              "  korean        15      0       11    191    0\n",
              "  thai          10     11        3      7   70"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion matrix for categorical data\n",
        "conf_mat(data = results, truth = cuisine, estimate = .pred_class)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c0HfPL16Lr6U"
      },
      "source": [
        "When dealing with multiple classes, it's generally more intuitive to visualize this as a heat map, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "HsAtwukyLsvt",
        "outputId": "3032a224-a2c8-4270-b4f2-7bb620317400",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC/VBMVEUAAAABAQECAgIDAwMEBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUWFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJycoKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6Ojo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29wcHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTW1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////zRGfuAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3deXxU9b3/8W+CglHArfa2WtfaWpeC1rZqFavi2nYIEjCIILK5IC0ujYosigglrCooFhfwotWWolURWxVbjBDSuNCWiqVoQIEEKPiDKnKNOY/fnJlMCHx49/b2nJlzBl6vP84530n8ztcz82ROJoM6j4gC56JeANHuEJCIQghIRCEEJKIQAhJRCAGJKISARBRCQCIKISARhRCQiEIISEQhBCSiEAISUQgBiSiEgEQUQkAiCiEgEYUQkIhCCEhEIQQkohACElEIAYkohHIMacumGLUu6gU0b/3GqFfQvFidmlgt5v+JZ3aOIfUfF6PO/EWM6jnp8Rh1xWMxauCsGPUT8czOMaQRC2PUpRti1F1/rItRd66OUXfVxqip4pkNpJgEJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECS7ZaQiitTu/rEkiggjWrXtuirg/6QPLrv2/u3Pn7E69FDqjrZPRvGPKFAmv7dA/Y7/s4Pgk8UFFJFe/drf3+TS3VWpJAWtndPpw5+f8H++5wyM1aQGv68JQJIP3YXTp56VcE5CxeOKzzupp+2d/0jhzSh6LD4QBrpSn75zI0FP4oc0tiiQ9OQBhSO95sVJaTy5GJSkBa1PWbs1O8XzIgTpP+0YJCOONR/CTrb/XbhMYe+unDhgiNaB3pJCgHSi63Kp8QH0rFH1ia3l7h3I4b0XKvRk9OQStsEmigMSHNb/ezeNKSSff9UW7v6xCPXRgpp/ahuV9y/zSt+6Y6SPvP9S7uGRMXwAX3ne96m8tIew1d63ivXlfR6YFvTMAuQjj3K315UOL9icLl/9AM3P2JI1Qs2xAjSiV/3t11b1ASeKRikha+sboT0g0Mjh1T5am0a0urWnfzxXe6VSCHdNnbj6usf9IoHvbPtsZKt/s9IxYM3eHO7bvWGlW/eNuvKT9d2WvL5uhtnZ4bZgDTcDXj+d2NadWscvv6NLwaaLpw3G2IEaaq7benyR/cZEHymwG82NEI667jVq1dECylZGlKlG+IPnnH3RQmpJrHG81ZUe8VzPK82sTIF6VnPq0usXJnYlPyZqXvFssTfPe9zLzNM/jOVnZL9JURIC0cVOVd4Vep67g9P//zCvUcDaYem75c8PzfWBp8oLEjtjypp4w7stzwOkJ51k/xBhRsaJaTKTp+n9sWLPG9jYnkKUvqwMpFqdsODncue+MDLDJPfW3FusrdDhHT/vmeOu6e0cIB/fI9zXxoXaLbdD9JvWl8wa/Y1LW6LD6SjCrpPm35pxO/aNUL6pZviD6rcT6OEtKhTfRpS5XZI6cPFiW2N37N+3sjOFduHuyoQpIpDj6tI7roWPpXczhs35PzCXkBq1toj261N7voXVsYG0htv+9tSNzsGkJ51E/3Ba25YlJBqEjWe9+7cXUBalXgn+fW1Xv1Hyd30IZlhFiDNdik45W5Y4w1XuIeBtL0/usH+7r/dlNhASve4CzRfSJAWu1v9wWw3NUpIXtmIug8HP7ALSN7QsvX187pufKnP8oZNw+7NDLMA6Ql3ub8b5W6bW/aQfzTODQHS9ircdf7uITcpNpCWLfO30115DCCt2f8Sf3C7q4gUUt3Irj3u/3RXkDaWl3YrW+o1PNmvS697/pkZZgHSgtbH+Jd2xe6x3+11sn90mbsHSNv7sO03/Eu7Xu7VuEB6u8X5/qBjwYIYQKq9omV1be3Ko04INNdu8Vm7G9xpd0+4rLDjwoV9XLvBZRcUnFQRMaQXJk/u4a6fPPnNOECqu9ud+/ATA1oUB58pGKTfjB9f6q4dP37R6r7unPK7z3B9A00XDNJzEyd2dwMnTqyqfeugw++acMpec4C0cNRJ++x95DULkkcjTmpbdMyAVwLNFgKk3unPkrmHYgGpbvq3i/b+2u0fBp8oGKSejWflgdUfjD6pzT7tAl3YBYV0ZeNiHqytXXhRm6LTgjnaTSCFG5/+lvHpbxWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSAckGJBmQVECyAUkGJBWQbECSAUkFJBuQZEBSxQRSzxEx6uRpMarzXffHqC73xajeUZ+N5vUXz+wcQ7rz5Rh18bAYdd6sV2LU9VEvoHk3vhSjbhfP7BxDemB9jLpqZozq/mbUF5fNGx31App397oY9YB4ZgMpJgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJFhKkP+5zUAizXPWfP+3HHu1uSx08cukhe/3XZTOSR7ee0Kbo6KtnRAup6mT3bBjzhAHp1Qu/2PqkCXXBJwoD0upbjmh59Ii64BOFCKk+sWSHcV2iZuebsgxp3ZkuWki9Wx7UCOk7hZdce7brPHPmDQVH9rzy665LpJAmFB0WG0gvtjzyrknnuuuDzxQGpE4tBj54hSsLPlGIkBr+vGVnSDvflGVIE1ueEymkYXv36p+GdLPr4Wv6xoyZXzlkevL16UtF/+lLUhiQXmxVPiU2kM7c/50NG9a1K6oNPFMIkH7p/EkS3wv+kpTFS7skpH/7e0OB9Je2t10RKaTyUTMbIZ1e9HD6phk9Bvu7s9zPI4RUvWBDfCDd83N/29e9G3imECB1afth8ElShXtp15CoGD6g73zPW3Fz10GvpS/tVg3vXjpijdf0pexBuuT4NdFCStYI6QvfTBrafuuMow/6TycM6c2G+EBKd87B6wLPEQKkw89dt642+DTrQv8ZqXjwBm9u160N/SZvrbstDWngpE8+HlPmZb6UPUgPF/5ufUwgzSg4t89/Fex37oP+TQ9PHHbGXoOA1LxH3IjgkwSHVFvQe+LRBQf0fi9+kJ71L+lWvpNY63mVaUibk3YWdm7IfCn5ja+emuyNsCH97QvXrI8LpAfdIUdfV3ZJ4Qn+TWXOHXzDfzzhbgnpyaILg78ghQDpfXfEKdNnD2zRIX6QFnnexsTy1zp97nmr0pCWDOvfr2eiPvOl5DdW90z217AhlR6+MjaQHnZtpiV3F7nhye2UG/qdVvAjIG2vvEXxmhCmCQ7pQ3fQiuTuWvfb2EGqTGmZ70N6PwWprsvsz7wqH1JlBtIuCg7pVwW/qKmp6X5QzYcxgDSz6Hh/e7Pr03jzD9wdQMp0rRu8Pox5QvgZqc1Z/vYpNynwTNmB9KdErectSEF6PXlV5z2efUj9XGMXxAHSN77kbwe7q+/rPcI/usH1BVJjNxZOCmGWDaFA+t6x/va/3f2BZ8oOpG09Jm9ZVZaCtCyxtGHBLYl12Yb0xly/C9vOfT0OkK50P01uz3Dl01oc5797d6ErA1K6X7ufBZ8kVQiQxrlfJbdd3eKYQvLevaFk0BuJFf5NMy7vMWXL4J51WYaULtqfkYb26dPBXdKnz/iZDx/VslO/77oOM2cWu6/36H16wbFR/kL2hcmTe7jrJ08OPlVwSLVfPXhyqrcDTxUCpA/bF910b7G7PPhMu9dn7SKGdG7j1eV1M2fef97+Lb5Y8kjyxquP3W+fr3R58D+dMwxIvRvX9VDgmYJDejdzCf7fgacK4yNCf7vqi3sfNWRN8Il2M0ih9B9DykZ8+lvGp79tQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLIBSQUkGZBsQFIBSQYkG5BUQJIByQYkFZBkQLJ1uyZGHXdhjDq2e9Sno3nfi3oBzfvh1THqEvHMzjGkSX+PUZd/EKOG/7IiRt3+txg1anWMmiqe2TmGdM+qGNUz6suE5o2cUxWjhtfEqFhdZ04Tz2wgxSQgyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSDIg2YCkApIMSDYgqYAkA5INSCogyYBkA5IKSLL8g1R72cEFLhWQch2QZPkH6bK9LriqXyog5TogyfIP0heezBYgIP1vAUmWf5D2rQFSVAFJln+Qzn4eSFEFJFn+QVry3QVAiiggyfIP0llHun2PTAWkXAckWf5BOvu8jo0BKdcBSZZ/kLIfkFRAkuUjpA3PT3/4t5uBlPuAJMs/SJ/fsLf/sYb9xgEp5wFJln+QxrsuD8974ecXuceAlOuAJMs/SCdck96XfgtIuQ5IsvyD1Oql9P7ZIiDlOiDJ8g/SfnPS+9mtgZTrgCTLP0hnnb3N331y5tlAynVAkuUfpBcKjrj6rmG9D27xMpByHZBk+QfJe+Yb/tvf7eZlyxGQZECS5SEkz1v9x+rarDECkg5IsryElOWApAKSLM8gHTfGO64pIOU6IMnyDNJpk73TmgJSrgOSLM8g5SQgqYAkyz9Ip/41vZ/NR4RyHpBk+QfJVad2n43cF0i5DkiyfIPktscrUs4DkizfIC251xWn/uuQ/Ud8AKRcByRZvkHyvIv+li1AQPrfApIs/yB5a+5LbtaNXAOknAckWf5BWvallsltjfvyciDlOiDJ8g9S52P/6O/+emwJkHIdkGT5B+ngR9P7nx8CpFwHJFn+QdrnifT+kbj+Hmlex0Nanzjmff/wD+3cL6OHVJb+dUGHqCG9kvnFxbiqqvu/c0DrE+5cHCWkuR0P2e+E0Stqam5Ir+rM6CFVneyeDWOefwvSGRd+7u/++Z3vZW6pTyyJEaRnWh4xbOzZ7prk4ZiiQ+MA6ZrCSX5PRg3p9dtTnV/4RNWEwuN+esvJ7uoIIT3d8oihYzq4q2tq+haO9ZsZOaQJRYflENK8wuMGjRra+6DCFzO3NPx5S4wgndH2rVWrak4qem/VM61GTYwDpMvbBp8jXRiXdvO/0LWq6quHvVZVtfDI1oFekoJBOr3tGzU1751U9Peabm0CTRQapBdblU/JISTvhXb+C3H7F0LFEx6kcff52yvd26te+92qWED64WHB50gXBqRuB75SVXnTBP/wR+4P0UEqv9ff9nJv1Vz85XhAql6wIaeQPG/dW2+tbzb0L+1WDe9eOmKNty3x0m1XXVflZcYNiYrhA/rO97xN5aU9hq/0vFeuK+n1wLamYRYgpetwUI2/iwWkDsetW7cq+DTrQoH0VIvbMoeLj/+vQFOF8WZDh4Peqznz6zU1y2IAKVmOIe2UD2ngpE8+HlOWPBz0kfdi57rM2CsevMGb23WrN6x887ZZV366ttOSz9fdODszTP7Dn3yY7NOwIU1zQ1bFBtLJR3dt6w4cUBMLSOceXpnaVzz78MV7j40a0v3u1pqadkdd2sYd2OevexKkXf4NWR/S5q2et7BzQ33iGc/7vHReZuwVP+t5dYmVKxObkj9Lda9Ylvh78uteZpj8h189NdkbIUOaWdSxJj6Qji7oMf3RkujftfN7qmBI+mCKc1+aGGyu4JAeLer4Xk3NUQWXTZ1WHId37XIHaZd/Q9aHtGRY/349E/X1icXJG659LDP2ihd53sbE8spEqtkND3Yue+IDLzNMfu/SW5OtCBfSqBY/XLEqPpCWLPW3l7unA88UHFLXfRt/LPrdhGEXFPaOFtJdLX64PLmrrPYH3dyTexCkXZaEVNdl9mdelQ8pCce7+snM2CuuTEFanNjW+M3r543sXLF9uKuCQurnBq5cFSNI6Z5yowLPERjSogPObzbq5WZECamvu+797aPH3AggLXk9eRXnPe5DSr7K/E/XlzPjDKRViXeS37jWq/8ouZs+JDPMCqRBhWObjmMBacUKf/uomxB4psCQprvh/u63tz7q7ya4oRFCur5wTPpg6VJ/O82N2YMg7desvZtBWpZY2rDglsS6+sTA9//nqZLNmXEGkje0bH39vK4bX+qzvGHTsHszw2xAesKN3D6IA6SlLS70dxcULIwe0iA3y9/N3+sU/y2HUjclOkiz3J3pg+oWHf3deQXz9yBIpaWl3Y/b+4ySzicXfGdwM0jejMt7TNkyuOeaxAu3lgx8w8uM6zKQNpaXditb6jU82a9Lr3v+mRlmAdJ7xxxUnqpy1dPl5Ze5a8rLX48W0rr+7twJPzvT9Q8+U2BIP3K/T+37ufY33XphwTcrI4P096MPSn2eYezCmqvc2WNGnu6uCjJdGJBemDy5h7t+8uQ3cwAp2eyTUn8T6Z0jnmsOqenwTTHH/6FAkJZkPlD20KorGo+mRgypduw32+zTPviFXQiQOhQ2fpbhzm+2LfrqNYF+HxsM0luZx2l6zXt3ndh6n28GurALBVLvzDMnN5BOeiq9n9o+g2dZ4r34QAo7Pv0t49Pfqn8LUsvG/wvFr1o13vDapXc3ACknAUmWf5AOvTzF5vNOXw5OBkj/t4Akyz9Id7iTfjxq1PXfcLcBKdcBSZZ/kBrKv+z/RPaF4fVAynVAkuUfpCSllVWLV3yeLUZA0gFJlo+QPql4ar33GZByH5BkeQhpXFvnKr3b+3Bpl/OAJMs/SA+5Tg8mIT2218+AlOuAJMs/SO2v9bYmIXlDTgBSrgOSLP8gtXo5Dem3RUDKdUCS5R+k1s+lIT3WFki5Dkiy/IN03nmf+pA2nXQhkHIdkGT5B2nBXsdc5/r03n/v14GU64Akyz9I3vxv+Z9s+O4fsuUISDIgyfIQkuetf+tt8ZdbgZTVgCTLO0jbvv18Fg0B6V8GJFneQfIOnQykqAKSLP8gPX/i01n8nB2Q/lVAkuUfpLPbub2+fKQfkHIdkGT5B+l73+/YGJByHZBk+Qcp+wFJBSRZ3kH6ePHr2XzrG0j/KiDJ8g3SxP2cazHwX/2Xu4GUvYAkyzNIv3RH3zysg/sJkCIJSLI8g/S9o/+Z3Pbd+yMgRRGQZHkGqfVwf1vlsvaBVSD9q4AkyzNI7uf+do37LZCiCEiyfIP0kL9d614EUhQBSQYkIP37AUmWb5CGVCZ7wU32d0DKdUCS5Ruk5gEp1wFJlmeQ7mgekHIdkGR5BiknAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAckGJBWQZECyAUkFJBmQbEBSAUkGJBuQVECSAcnWuWeMOvaqGHXKhV1i1HeuiFE/6BOjLhbP7BxDum91jOr1jxg1avHaGJWYGqPGRP3YNC8mr0hAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgFJBSQZkGxAUgFJBiQbkFRAkgHJBiQVkGRAsgWFVNHe/drf3+RSnRU5pIqL9t/nW4+HMFFgSAvbuzk7HkQDacQRbnDqYOBXW7b82k073hYZpNAep1Ag1SfejBbS2KJD05AGFI73mxU1pOq2x4ybdk7BrOAzBYVUnjw1c3Y4iAZS95YHptH0LTistPTQvW5pfltkkMJ7nHYLSM+1Gj05Dam0TaCJQoPUbd+//uMf6046akPgmQJCer7VmHtSfpoOooF0896X9UyjOfiASVOnTmh7XPPbIoMU3uOULUj1uYS08JXVjZB+cGgsIK1r3dnfjXZ/CDxVQEiL5q9N+2k6iAbSHUOmptH8zHXwx+cXjNt+W2SQQnycQoNUP+zO+k3jruwx9P3k8OV+E71N5aU9hq/0vFXDu5eOWOM1JCqGD+g7PyuQkjVCOuu41atXRA/pDTfM3z3n7g88VfA3G5r8RAkpWRrN3e48f9DN3bj9tsgghfg4hQZpctmn3s0jN219pPtmr9NNKz72hpVv3jbryk+9gZM++XhMmecVD97gze26Nfnt/6hK9v+yAqn9USVt3IH9lkcMaa67199VuuGBp9rdIN1XdIQ/OM31jwGkEB+nsCA9PnCztyKRfAH6tORlr/gpz1uZ2OR5Dd0rvM1JOws7N3jFz3penf8d3qunJnsjK5COKug+bfqlkb9rN8dN83dvulsCT7W7QZp6vutw56gftHF9YwApxMcpJEhjE3/xvNc7+T8ZXT3LK37N8yoTqeD0dT8AABEKSURBVGZ7S4b179czUe8VL/K8jYnlye9YcV+yD7MC6Y23/W2pmx0tpLnuHn+3yI0IPNVuB+ne7xU4d/wV7toYQArxcQoJUr8RN9Y3QhrwuFdc6XmLE9tSX6vrMvszr8qHVJmBtIvCgpTucXdntJDecLf7u2fSf+AFareDNHXq2LK7p3Z1w2IAKcTHKSRI1Vv6POq9l6jxvK0l81NmViXeSX5lrfd68qrOezxXkJYt87fTXXm0kNYf8AN/N9xVBp5qN4Tk126/+2IAKcTHKbQ3G5Z2fssrG/nRx9N6fpwy4w0tW18/r+vGZYmlDQtuSazLCaS3W5zvDzoWLIgW0j96tXr7H/9Yc/SJwWfa7SCd8YV7pk4dUniOxZV7SCE+TuH9HmlWr4/W392tx8jkDz8pSBvLS7uVLfW8GZf3mLJlcM+6LEL6zfjxpe7a8eMXre7rzim/+wzXN9B0IUD688FHjJ78rb2eDT5TQEjPTZjQ3V03YcLipoNoIN3Uo8fprmOPHndOvbbg2J6Xtj64vPltkUEK73HaLT5r1zP9CTv3wOoPRp/UZp92gS7swvmsXdXFbYpOD+HxCQqpV+OpmdZ0EA2ksxrvvs/UqX2/snfr747e8baoIIX3OO0WkEKOT3/L+PS3Ckg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEgqINmAJAOSCkg2IMmApAKSDUgyIKmAZAOSDEiqmEC6tFeM+nqfGHXqpb1j1FEdYlQi6semeReLZ3aOIU2tjVG9o/5zv3l3vLkhRo2qi1E3VMeou8QzG0gxCUgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSDUgqIMmAZAOSCkgyINmApAKSDEg2IKmAJAOSLSikhe3d06mD31+w/z6nzIwYUnI1c3Y8iBjSM2cf3PaUaeuDTxQc0t9cYzOjhfRqZh3jq6uf7NCm1YkTYg2puHKHYX1iSVYglRcdmoa0qO0xY6d+v2BGpJD81czZ4SBiSE8Uths7/nR3WxwgfTgpVXHh76OFtGhoqvMLf1H9dOvDb73rtILxcYX0p+UGUsOft2QD0txWP7s3Dalk3z/V1q4+8ci1EUJ6vtWYe1J+mg6ihnT8kR9u2LD22LbBX5LCurRb/qW+wScJ4dLu94d0q66+uOjF6uqqrx32x5hCGjnPQJIFg1T5am0a0urWnfzxXe6VCCEtmr827afpIGJI60Y/7u8ud6tiA6nfwX8LPkkIkC478NXqqn3P9w9vck/EE9Ltnbrc4BW/dEdJn/met2p499IRa7J2aVfbCKnSDfEHz7j7IoSUrMlPLCClW3/yYcEnCQlSxV7jQ5glOKRftRhSXf20G+gf/9zdEU9IXj//FWnQO9seK9nqDZz0ycdjyhohrZ6TbF02ID3rJvmDCjcUSDu0ZsmLXVvOCD5PSJB+eMyaEGYJDuncw6uqq6e7YSlU7vo4Q5rjebWJld7mrZ63sHNDGtKrpyZ7IxuQfumm+IMq91Mg7dAc5w7/RQjzhAOpomBCGNMEhvSrgtuT26lupD/4jRsQZ0iLPG9jYrm3ZFj/fj0T9dl/RZroD15zw4C0Q+8+ce+lhTcEnyccSH1bvxfGNIEhddt3QbX/ijQ0pcoNijOkyhSkui6zP/OqMpB2UUiQFrtb/cFsF2i+3RCS34/dy4HnCAXS6oOKw5gmMKTFB6TeZXjGXevvHnB3xR/S650bPO/x7ENas/8l/uB2VwGk7S2b8JK/e8LdEw9Iz7l7w5gmMKSH0m8vVLU9x99d734VU0gDH9mcgbQssbRhwS2JddmGVHtFy+ra2pVHnRBort0N0nt7n7EuubvGzYkHpOFufhjTBIb048Y3vDu3fK66euFXvhZosixCeq7rgAwkb8blPaZsGdxzTXYgPTdxYnc3cOLEqtq3Djr8rgmn7DUnSkjPTZjQ3V03YcLipoOIIW0oc6ePntCl4Dvr4gHpcrcijGkCQ0q4Ban93AO+fNPQE1tMiyuk/0vBIF3Z+LGpB2trF17Upui0YI6CQurVuJppTQdRQ9ow7TsH7nf8kJXBJwoF0oWFtWFMExhSh8LGzzL8+uz99jk5mKPdA1LI8elvGZ/+VgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJBSQbkGRAUgHJBiQZkFRAsgFJBiQVkGxAkgFJFRNIM2bFqBujXkDzhk2JegXN+0nUC2herB6nqeKZnWNIRLtnQCIKISARhRCQiEIISEQhBCSiEAISUQgBiSiEgEQUQkAiCiEgEYUQkIhCCEhEIQQkohDKS0hT74l6Bc16YXRd1EvY3l9HL456Cdv7dPQvol5Cs2aMzur0eQkpcWHUK2jW3acuj3oJ23v51FlRL2F7W04dFPUSmtX721mdHkhBA5IKSHEPSCogyYBkA5IKSDIgEcU/IBGFEJCIQig/IBVXpnb1iSURL8QsoS5Rk/NVxeA0mOoTb0a9BF3j0ydTVs5fXkFq+POWiBdilpCElPNVxeA0mGIL6U/LDaSsnL+8ghTDkpCiXkIs2gWk+ijWYRo5LzdPn5hDWj+q2xX3b/OKX7qjpM98/zW5IVExfEDf+Z63qby0x/CVnvfKdSW9HtjWNMx2zZew4uaug15LX9qtGt69dMQar+lL2V5D5g63JV667arrqjyzgFyfHh9S/bA76zeNu7LH0PeTw5f7TWy615yenR27vVOXGzJPn8w69sRLu9vGblx9/YNe8aB3tj1WstU/A8WDN3hzu271hpVv3jbryk/Xdlry+bobZ2eGWV9QsyU09Ju8te62NKSBkz75eEyZ17S6rK+h8Q7rE4M+8l7sXGcWkOvT40OaXPapd/PITVsf6b7Z63TTio+b7jWnZ2en+vmvSOmnz/aTtsdBqkmsSf7BX+0Vz/G82sTK1LP4Wf96auXKxKbkxW73imWJv3ve515mmPUVNVvCO4m1nleZhrQ5+exY2Lkh86Xsr6HxDusTzyT/9Uvn7byAnJ+eJKTHB272Vvj/7p+WvOwVP+Vtv9ecnp2dSkFKP322n7Q9DlJlp89T++JFnrcxsTz1LE4fViZSzW54sHPZEx94mWHWV9RsCa/5i1uVhrRkWP9+PRP1mS9lfw2Nd1if8D/tfe1jOy8g56enPjE28RfPe72T/5PR1bO84te87fea07OzUylIjffbdNL2OEiLOqV/YvV/WsxASh8uTmxr/J7180Z2rtg+zHLNljDfh/R+ClJdl9mfeVX+U6UyN5Ayd1ifSD5HvKuf3HkBOT899Yl+I26sb4Q04PHUOjL3mtuzs1P95jU9fbaftD0OUo3/nti7c3cBaVXineTX13r1HyV304dkhlmv2RL+lKj1vAUpSK8nr1u8x3MIKXOH9f6rzP90fXnnBeT89NQnqrf0edR7z3/AtpbMT60jc6+5PTs71QzS9pO2x0HyykbUfTj4gV1A8oaWra+f13XjS32WN2wadm9mmPUFNVvCth6Tt6wqS0FalljasOCWxLqcQcrcYX1i4Pv/81TJZrOAXJ8e/82GpZ3f8spGfvTxtJ4fp99xbrzX3J6dnRr4yObM/W4/aXsepLqRXXvc/+muIG0sL+1WttRreLJfl173/DMzzHrNl/DuDSWD3kis8G+acXmPKVsG96zLFaTMHa5JvHBrycA3PLOAXJ+e1O+RZvX6aP3d3XqM/LDxVzeZe83p2dmp57oOaHrAmk7angeJdlGzP1Fj+4GCPS4g5V31yxLvNR0DKSYBKe967dK7GzLHQIpLQCIKISARhRCQiEIISEQhBCSiEAJS/naNy3Tarr+h45G5XdCeHJDyt99PmTLlJ64kubUf637bf2CBlLuAlN/93k1uOm7+Ce/7gJTbgJTfZSCd8f0XvvJtr317/7j4YO+i5PXeqV7Hr664uPUh3ddFusI9JCDldxlI32934uTntkP6W7Gr/qvX8ah2Y54f4i6LdIV7SEDK7zKQOrqnk9smSF6/1KWdm5Pcdjg4uuXtOQEpv2uCtNdnnoW0j/+hvN4F0S1vzwlI+V0TpC/7250hpd5s6MdjnIM4yfldE6SUGSBFFic5v9sR0inf9LenAyn3cZLzux0hnfeF5GZtURJSf/cZkHIZJzm/2xHSaDfmg8qzT05CGuFGzgZSDuMk53c7Qtp6w2Gt2s8d1NbzPjil6BQg5TBOMlEIAYkohIBEFEJAIgohIBGFEJCIQghIRCEEJKIQAhJRCAGJKISARBRCQCIKof8PGdbdIfYEXsAAAAAASUVORK5CYII=",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 420,
              "width": 420
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "results %>% \n",
        "  conf_mat(cuisine, .pred_class) %>% \n",
        "  autoplot(type = \"heatmap\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oOJC87dkLwPr"
      },
      "source": [
        "The darker squares in the confusion matrix plot indicate high numbers of cases, and you can hopefully see a diagonal line of darker squares indicating cases where the predicted and actual label are the same.\n",
        "\n",
        "Let's now calculate summary statistics for the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "OYqetUyzL5Wz",
        "outputId": "6a84d65e-113d-4281-dfc1-16e8b70f37e6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 13 Ã— 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>accuracy            </td><td>multiclass</td><td>0.7880435</td></tr>\n",
              "\t<tr><td>kap                 </td><td>multiclass</td><td>0.7276583</td></tr>\n",
              "\t<tr><td>sens                </td><td>macro     </td><td>0.7780927</td></tr>\n",
              "\t<tr><td>spec                </td><td>macro     </td><td>0.9477598</td></tr>\n",
              "\t<tr><td>ppv                 </td><td>macro     </td><td>0.7585583</td></tr>\n",
              "\t<tr><td>npv                 </td><td>macro     </td><td>0.9460080</td></tr>\n",
              "\t<tr><td>mcc                 </td><td>multiclass</td><td>0.7292724</td></tr>\n",
              "\t<tr><td>j_index             </td><td>macro     </td><td>0.7258524</td></tr>\n",
              "\t<tr><td>bal_accuracy        </td><td>macro     </td><td>0.8629262</td></tr>\n",
              "\t<tr><td>detection_prevalence</td><td>macro     </td><td>0.2000000</td></tr>\n",
              "\t<tr><td>precision           </td><td>macro     </td><td>0.7585583</td></tr>\n",
              "\t<tr><td>recall              </td><td>macro     </td><td>0.7780927</td></tr>\n",
              "\t<tr><td>f_meas              </td><td>macro     </td><td>0.7641862</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 13 Ã— 3\n",
              "\\begin{tabular}{lll}\n",
              " .metric & .estimator & .estimate\\\\\n",
              " <chr> & <chr> & <dbl>\\\\\n",
              "\\hline\n",
              "\t accuracy             & multiclass & 0.7880435\\\\\n",
              "\t kap                  & multiclass & 0.7276583\\\\\n",
              "\t sens                 & macro      & 0.7780927\\\\\n",
              "\t spec                 & macro      & 0.9477598\\\\\n",
              "\t ppv                  & macro      & 0.7585583\\\\\n",
              "\t npv                  & macro      & 0.9460080\\\\\n",
              "\t mcc                  & multiclass & 0.7292724\\\\\n",
              "\t j\\_index              & macro      & 0.7258524\\\\\n",
              "\t bal\\_accuracy         & macro      & 0.8629262\\\\\n",
              "\t detection\\_prevalence & macro      & 0.2000000\\\\\n",
              "\t precision            & macro      & 0.7585583\\\\\n",
              "\t recall               & macro      & 0.7780927\\\\\n",
              "\t f\\_meas               & macro      & 0.7641862\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 13 Ã— 3\n",
              "\n",
              "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
              "|---|---|---|\n",
              "| accuracy             | multiclass | 0.7880435 |\n",
              "| kap                  | multiclass | 0.7276583 |\n",
              "| sens                 | macro      | 0.7780927 |\n",
              "| spec                 | macro      | 0.9477598 |\n",
              "| ppv                  | macro      | 0.7585583 |\n",
              "| npv                  | macro      | 0.9460080 |\n",
              "| mcc                  | multiclass | 0.7292724 |\n",
              "| j_index              | macro      | 0.7258524 |\n",
              "| bal_accuracy         | macro      | 0.8629262 |\n",
              "| detection_prevalence | macro      | 0.2000000 |\n",
              "| precision            | macro      | 0.7585583 |\n",
              "| recall               | macro      | 0.7780927 |\n",
              "| f_meas               | macro      | 0.7641862 |\n",
              "\n"
            ],
            "text/plain": [
              "   .metric              .estimator .estimate\n",
              "1  accuracy             multiclass 0.7880435\n",
              "2  kap                  multiclass 0.7276583\n",
              "3  sens                 macro      0.7780927\n",
              "4  spec                 macro      0.9477598\n",
              "5  ppv                  macro      0.7585583\n",
              "6  npv                  macro      0.9460080\n",
              "7  mcc                  multiclass 0.7292724\n",
              "8  j_index              macro      0.7258524\n",
              "9  bal_accuracy         macro      0.8629262\n",
              "10 detection_prevalence macro      0.2000000\n",
              "11 precision            macro      0.7585583\n",
              "12 recall               macro      0.7780927\n",
              "13 f_meas               macro      0.7641862"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Summary stats for confusion matrix\n",
        "conf_mat(data = results, truth = cuisine, estimate = .pred_class) %>% \n",
        "summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43t7vz8vMJtW"
      },
      "source": [
        "If we narrow down to some metrics such as accuracy, sensitivity, ppv, we are not badly off for a start ğŸ¥³!\n",
        "\n",
        "## 4. Digging Deeper\n",
        "\n",
        "Let's ask one subtle question: What criteria is used to settle for a given type of cuisine as the predicted outcome?\n",
        "\n",
        "Well, Statistical machine learning algorithms, like logistic regression, are based on `probability`; so what actually gets predicted by a classifier is a probability distribution over a set of possible outcomes. The class with the highest probability is then chosen as the most likely outcome for the given observations.\n",
        "\n",
        "Let's see this in action by making both hard class predictions and probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "xdKNs-ZPMTJL",
        "outputId": "68f6ac5a-725a-4eff-9ea6-481fef00e008",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 Ã— 7</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cuisine</th><th scope=col>.pred_class</th><th scope=col>.pred_chinese</th><th scope=col>.pred_indian</th><th scope=col>.pred_japanese</th><th scope=col>.pred_korean</th><th scope=col>.pred_thai</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>indian</td><td>thai  </td><td>1.551259e-03</td><td>0.4587877</td><td>5.988039e-04</td><td>2.428503e-04</td><td>5.388194e-01</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td><td>2.637133e-05</td><td>0.9999488</td><td>6.648651e-07</td><td>2.259993e-05</td><td>1.577948e-06</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td><td>1.049433e-03</td><td>0.9909982</td><td>1.060937e-03</td><td>1.644947e-05</td><td>6.874989e-03</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td><td>6.237482e-02</td><td>0.4763035</td><td>9.136702e-02</td><td>3.660913e-01</td><td>3.863391e-03</td></tr>\n",
              "\t<tr><td>indian</td><td>indian</td><td>1.431745e-02</td><td>0.9418551</td><td>2.945239e-02</td><td>8.721782e-03</td><td>5.653283e-03</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A tibble: 5 Ã— 7\n",
              "\\begin{tabular}{lllllll}\n",
              " cuisine & .pred\\_class & .pred\\_chinese & .pred\\_indian & .pred\\_japanese & .pred\\_korean & .pred\\_thai\\\\\n",
              " <fct> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t indian & thai   & 1.551259e-03 & 0.4587877 & 5.988039e-04 & 2.428503e-04 & 5.388194e-01\\\\\n",
              "\t indian & indian & 2.637133e-05 & 0.9999488 & 6.648651e-07 & 2.259993e-05 & 1.577948e-06\\\\\n",
              "\t indian & indian & 1.049433e-03 & 0.9909982 & 1.060937e-03 & 1.644947e-05 & 6.874989e-03\\\\\n",
              "\t indian & indian & 6.237482e-02 & 0.4763035 & 9.136702e-02 & 3.660913e-01 & 3.863391e-03\\\\\n",
              "\t indian & indian & 1.431745e-02 & 0.9418551 & 2.945239e-02 & 8.721782e-03 & 5.653283e-03\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A tibble: 5 Ã— 7\n",
              "\n",
              "| cuisine &lt;fct&gt; | .pred_class &lt;fct&gt; | .pred_chinese &lt;dbl&gt; | .pred_indian &lt;dbl&gt; | .pred_japanese &lt;dbl&gt; | .pred_korean &lt;dbl&gt; | .pred_thai &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|\n",
              "| indian | thai   | 1.551259e-03 | 0.4587877 | 5.988039e-04 | 2.428503e-04 | 5.388194e-01 |\n",
              "| indian | indian | 2.637133e-05 | 0.9999488 | 6.648651e-07 | 2.259993e-05 | 1.577948e-06 |\n",
              "| indian | indian | 1.049433e-03 | 0.9909982 | 1.060937e-03 | 1.644947e-05 | 6.874989e-03 |\n",
              "| indian | indian | 6.237482e-02 | 0.4763035 | 9.136702e-02 | 3.660913e-01 | 3.863391e-03 |\n",
              "| indian | indian | 1.431745e-02 | 0.9418551 | 2.945239e-02 | 8.721782e-03 | 5.653283e-03 |\n",
              "\n"
            ],
            "text/plain": [
              "  cuisine .pred_class .pred_chinese .pred_indian .pred_japanese .pred_korean\n",
              "1 indian  thai        1.551259e-03  0.4587877    5.988039e-04   2.428503e-04\n",
              "2 indian  indian      2.637133e-05  0.9999488    6.648651e-07   2.259993e-05\n",
              "3 indian  indian      1.049433e-03  0.9909982    1.060937e-03   1.644947e-05\n",
              "4 indian  indian      6.237482e-02  0.4763035    9.136702e-02   3.660913e-01\n",
              "5 indian  indian      1.431745e-02  0.9418551    2.945239e-02   8.721782e-03\n",
              "  .pred_thai  \n",
              "1 5.388194e-01\n",
              "2 1.577948e-06\n",
              "3 6.874989e-03\n",
              "4 3.863391e-03\n",
              "5 5.653283e-03"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make hard class prediction and probabilities\n",
        "results_prob <- cuisines_test %>%\n",
        "  select(cuisine) %>% \n",
        "  bind_cols(mr_fit %>% predict(new_data = cuisines_test)) %>% \n",
        "  bind_cols(mr_fit %>% predict(new_data = cuisines_test, type = \"prob\"))\n",
        "\n",
        "# Print out results\n",
        "results_prob %>% \n",
        "  slice_head(n = 5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2tWVHMeLMYdM"
      },
      "source": [
        "Much better!\n",
        "\n",
        "âœ… Can you explain why the model is pretty sure that the first observation is Thai?\n",
        "\n",
        "## **ğŸš€Challenge**\n",
        "\n",
        "In this lesson, you used your cleaned data to build a machine learning model that can predict a national cuisine based on a series of ingredients. Take some time to read through the [many options](https://www.tidymodels.org/find/parsnip/#models) Tidymodels provides to classify data and [other ways](https://parsnip.tidymodels.org/articles/articles/Examples.html#multinom_reg-models) to fit multinomial regression.\n",
        "\n",
        "#### THANK YOU TO:\n",
        "\n",
        "[`Allison Horst`](https://twitter.com/allison_horst/) for creating the amazing illustrations that make R more welcoming and engaging. Find more illustrations at her [gallery](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
        "\n",
        "[Cassie Breviu](https://www.twitter.com/cassieview) and [Jen Looper](https://www.twitter.com/jenlooper) for creating the original Python version of this module â™¥ï¸\n",
        "\n",
        "<br>\n",
        "Would have thrown in some jokes but I donut understand food puns ğŸ˜….\n",
        "\n",
        "<br>\n",
        "\n",
        "Happy Learning,\n",
        "\n",
        "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lesson_11-R.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.0.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
